# python-toxic-text-classifier
Capstone project at Western Governors University.

For this project, I am making a toxic comment classifier. The purpose
of this project is to build a machine learning model that can take a 
comment and determine if it is toxic in some way. It will break the 
comments down into the categories of toxic, severe_toxic, obscene,
threat, insult, and/or identity_hate.

This project requires the following third-party modules:
tkinter
pandas
joblib
Sci-Kit Learn
MatPlotLib
Numpy
PyQt5
NLTK

Additional requirements:
After installing NLTK, open a Python terminal.
Type the following commands:
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')